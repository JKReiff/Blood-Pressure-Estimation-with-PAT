{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neurokit2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m savgol_filter\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatistics\u001b[39;00m \n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneurokit2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnk\u001b[39;00m \u001b[38;5;66;03m#peak detect from ecg and ppg usw\u001b[39;00m\n\u001b[1;32m     10\u001b[0m record \u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     11\u001b[0m resultsPTT \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neurokit2'"
     ]
    }
   ],
   "source": [
    "#################### Feature-Extraktion Code ###################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "import statistics \n",
    "import neurokit2 as nk #peak detect from ecg and ppg usw\n",
    "\n",
    "record =[]\n",
    "resultsPTT = []\n",
    "resultsPTTs = []\n",
    "resultsPTTv =[]\n",
    "HR =[]\n",
    "BP_sys =[]\n",
    "BP_dia = []\n",
    "PTTstd = []\n",
    "PTTsstd = []\n",
    "PTTvstd = []\n",
    "\n",
    "subject_info = pd.read_csv(\"PhysioNet_PTT_Dataset/subjects_info.csv\")\n",
    "personal_data = pd.DataFrame([])\n",
    "\n",
    "time_span = 5000 #10 seconds anlayse\n",
    "\n",
    "#schlechte Daten werden herausgenommen\n",
    "notgoodWalkStart = [2,7,8,10,11,12,13,14,19,20]\n",
    "notgoodWalkEnd = [1,2,4,6,7,8,9,10,11,12,13,14,15,16,19,20]\n",
    "notgoodRunStart = [1,2,6,8,9,11,12,19]   #12 the valley is not good \n",
    "notgoodRunEnd = [2,8,9,11,12,17,19,20]  #17 is actually okay but needs a additional filter \n",
    "\n",
    "\n",
    "for j in range(3):\n",
    "    for k in range(2):   # first goes for start 1-22 and then end 1-22 \n",
    "     #Iterate from 1 to 22\n",
    "        for i in range(1, 23):\n",
    "            \n",
    "\n",
    "            if j == 0:\n",
    "                action = \"sit\"\n",
    "            elif j ==1:\n",
    "                action = \"walk\"\n",
    "            else:\n",
    "                action = \"run\"\n",
    "\n",
    "            while action == \"walk\" and k==0 and i in notgoodWalkStart:\n",
    "                i += 1\n",
    "            while action == \"walk\" and k==1 and i in notgoodWalkEnd:\n",
    "                i += 1\n",
    "            while action == \"run\" and k==0 and i in notgoodRunStart:\n",
    "                i += 1\n",
    "            while action == \"run\" and k==1 and i in notgoodRunEnd:\n",
    "                i += 1\n",
    "                \n",
    "            df = pd.read_csv(\"PhysioNet_PTT_Dataset/s\" + str(i) + \"_\" + action +\".csv\")    \n",
    "\n",
    "            if k ==0:\n",
    "                pos = \"start\"\n",
    "                df_neu = df[0:time_span]\n",
    "            else:\n",
    "                pos = \"end\"\n",
    "                df_neu = df.tail(time_span)\n",
    "\n",
    "            uno = df_neu['pleth_1']\n",
    "            dos = df_neu['pleth_2']\n",
    "            tres= df_neu['pleth_3']\n",
    "\n",
    "            quatro = df_neu['pleth_4']\n",
    "            cinco = df_neu['pleth_5']\n",
    "            seis = df_neu['pleth_6']\n",
    "            # use the zip() function to combine the arrays\n",
    "            combinedDist= zip(uno, dos ,tres)\n",
    "            combinedProx = zip(quatro, cinco, seis)\n",
    "\n",
    "            # use a list comprehension to calculate the median of each triplet of elements\n",
    "            meanDist = [ (x+y+z)/3 for x, y, z in combinedDist ]\n",
    "\n",
    "            # Finde Peak / Maximum of PPG \n",
    "            signals, info = nk.ppg_process(dos, sampling_rate=500)\n",
    "            PeaksPPG = info['PPG_Peaks']\n",
    "\n",
    "            # Find steepest Ascent \n",
    "            steepestAscent= -np.diff(signals['PPG_Clean'])   #derivation of the signal\n",
    "            siganlsStepAsc, infoS = nk.ecg_process(steepestAscent, sampling_rate=500)  # finding the peaks of the derivation therefore the steepest ascent\n",
    "            SteepAsc = infoS['ECG_R_Peaks']\n",
    "\n",
    "            # Find valley / Minimum of PPG\n",
    "            mirrored_PPG_raw = np.array(dos)\n",
    "            mirrored_PPG_raw = (1/mirrored_PPG_raw)*max(mirrored_PPG_raw)# mirroring the signal an normalizing to 1)\n",
    "            signalsValleys, inf = nk.ppg_process(mirrored_PPG_raw, sampling_rate=500)\n",
    "            ValleyPPG = inf['PPG_Peaks']\n",
    "\n",
    "            SignalPeaksECG, ECGInfo = nk.ecg_process(df_neu[\"ecg\"],sampling_rate=500)\n",
    "            #PeaksECG = ECGInfo[\"ECG_R_Peaks\"]\n",
    "            p = df_neu['peaks']\n",
    "            PeaksECG = p[p==1]\n",
    "            PeaksECG = np.array(PeaksECG.index)\n",
    "\n",
    "            if PeaksECG[1]> 100000:    #if end of data set is observed then we need to zero the data to calculate\n",
    "                PeaksECG = PeaksECG-(len(df)-time_span)\n",
    "        \n",
    "            #Plot that shit\n",
    "            print(\"Person: \",i)\n",
    "            print(\"Action:\",action)\n",
    "            if k == 0:\n",
    "                print(\"Start\")\n",
    "            else: \n",
    "                print(\"End\")\n",
    "\n",
    "            #changing dataframe so that peaks are on the ppg signal as a cross \n",
    "            pPPG = signals['PPG_Peaks']\n",
    "            pSAc = siganlsStepAsc['ECG_R_Peaks']\n",
    "            pV   = signalsValleys['PPG_Peaks']\n",
    "\n",
    "            pPPG.loc[signals['PPG_Peaks'] == 1] = signals['PPG_Clean']\n",
    "            pSAc.loc[siganlsStepAsc['ECG_R_Peaks'] == 1] = signals['PPG_Clean']\n",
    "            pV.loc[signalsValleys['PPG_Peaks'] == 1] = signals['PPG_Clean']\n",
    "            \n",
    "            pPPG = pPPG.loc[pPPG != 0].to_frame()\n",
    "            pSAc= pSAc.loc[pSAc != 0].to_frame()\n",
    "            pV= pV.loc[pV != 0].to_frame()\n",
    "\n",
    "            #plot that shit\n",
    "            plt.plot(signals['PPG_Clean'])\n",
    "            plt.plot(np.arange(0, time_span),df_neu['peaks']*500, label=\"ECG Peaks\")     #SignalPeaksECG['ECG_R_Peaks']\n",
    "            plt.scatter(pPPG.index,pPPG,label=\"PPG Peaks\",marker = \"x\")\n",
    "            plt.scatter(pSAc.index, pSAc,label=\"PPG Steepest Ascent\",marker = \"x\")\n",
    "            plt.scatter(pV.index, pV,label=\"PPG: Valleys\",marker = \"x\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "            print(\"PeaksECG:\", PeaksECG)\n",
    "            print(\"PeaksPPG:\", PeaksPPG)\n",
    "            print(\"SteepAsc:\", SteepAsc)\n",
    "            print(\"ValleyPPG:\", ValleyPPG)\n",
    "\n",
    "\n",
    "            #a little bit of filtering ect to detect only the peaks which are relevant\n",
    "            if PeaksECG[0] > PeaksPPG[0]:\n",
    "                PeaksPPG = np.delete(PeaksPPG,[0])\n",
    "\n",
    "            elif  PeaksPPG[0] - PeaksECG[0] >260:\n",
    "                PeaksECG = np.delete(PeaksECG,[0])\n",
    "\n",
    "            if PeaksPPG[0] > SteepAsc[0]:\n",
    "                SteepAsc = np.delete(SteepAsc,[0])\n",
    "            \n",
    "            if SteepAsc[0] > ValleyPPG[0]:\n",
    "                ValleyPPG = np.delete(ValleyPPG,[0])\n",
    "\n",
    "            print(\"PeaksECG Korr.:\", PeaksECG)  \n",
    "            print(\"PeaksPPG Korr.:\", PeaksPPG)\n",
    "            print(\"SteepASc Korr.:\", SteepAsc)\n",
    "            print(\"ValleyPPG Korr.:\", ValleyPPG)\n",
    "            \n",
    "            PTT = np.array([x - y for x, y in zip(PeaksPPG, PeaksECG)])   #PTT =  PeaksPPG - PeaksECG\n",
    "            print(\"PTT:\", PTT)\n",
    "        #delete the outliers of PTT\n",
    "            mean = np.mean(PTT)\n",
    "            standard_deviation = np.std(PTT)\n",
    "            distance_from_mean = abs(PTT - mean)\n",
    "            max_deviations = 2\n",
    "            not_outlier = distance_from_mean < max_deviations * standard_deviation\n",
    "            PTT_no_outliers = PTT[not_outlier]\n",
    "            #print(\"PTT_no_outliers: \", PTT_no_outliers)\n",
    "\n",
    "            PTTs = np.array([x - y for x, y in zip(SteepAsc, PeaksECG)])\n",
    "            print(\"PTTs:\", PTTs)\n",
    "        #delete the outliers of PTTs\n",
    "            mean = np.mean(PTTs)\n",
    "            standard_deviation = np.std(PTTs)\n",
    "            distance_from_mean = abs(PTTs - mean)\n",
    "            max_deviations = 2\n",
    "            not_outlier = distance_from_mean < max_deviations * standard_deviation\n",
    "            PTTs_no_outliers = PTTs[not_outlier]\n",
    "            #print(\"PTTs_no_outliers: \", PTTs_no_outliers)\n",
    "\n",
    "            PTTv =  np.array([x - y for x, y in zip(ValleyPPG, PeaksECG)])\n",
    "            print(\"PTTv:\", PTTv)\n",
    "        #delete the outliers of PTTv\n",
    "            mean = np.mean(PTTv)\n",
    "            standard_deviation = np.std(PTTv)\n",
    "            distance_from_mean = abs(PTTv - mean)\n",
    "            max_deviations = 2\n",
    "            not_outlier = distance_from_mean < max_deviations * standard_deviation\n",
    "            PTTv_no_outliers = PTTv[not_outlier]\n",
    "            #print(\"PTTv_no_outliers: \",PTTv_no_outliers)\n",
    "\n",
    "\n",
    "\n",
    "            print(\"Mean PTT (-outliers):\",statistics.mean(PTT_no_outliers))\n",
    "            print(\"Mean PTTs (-outliers):\",statistics.mean(PTTs_no_outliers))\n",
    "            print(\"Mean PTTv (-outliers):\",statistics.mean(PTTv_no_outliers))\n",
    "            print(\"Heart Rate HR:\", statistics.mean(SignalPeaksECG[\"ECG_Rate\"]))\n",
    "\n",
    "\n",
    "        #append peak-positions to list\n",
    "            resultsPTT = np.append(resultsPTT, statistics.mean(PTT_no_outliers))\n",
    "            PTTstd = np.append(PTTstd, np.std(PTT_no_outliers))\n",
    "            resultsPTTs = np.append(resultsPTTs, statistics.mean(PTTs_no_outliers))\n",
    "            PTTsstd = np.append(PTTsstd, np.std(PTTs_no_outliers))\n",
    "            resultsPTTv = np.append(resultsPTTv, statistics.mean(PTTv_no_outliers))\n",
    "            PTTvstd = np.append(PTTvstd, np.std(PTTv_no_outliers))\n",
    "            HR = np.append(HR, statistics.mean(SignalPeaksECG[\"ECG_Rate\"]))\n",
    "            record = np.append(record, \"s\" + str(i) + \"_\" + action + \"_\" + pos)\n",
    "\n",
    "\n",
    "            subject_row = subject_info[subject_info['record'] == \"s\"+ str(i)+ \"_\" + action]    #takes the current row of the for loop\n",
    "\n",
    "            if pos == \"start\":\n",
    "                BP_sys = np.append(BP_sys, subject_row[\"bp_sys_start\"])\n",
    "                BP_dia = np.append(BP_dia, subject_row[\"bp_dia_start\"])\n",
    "\n",
    "            elif pos ==\"end\":\n",
    "                BP_sys = np.append(BP_sys, subject_row[\"bp_sys_end\"])\n",
    "                BP_dia = np.append(BP_dia, subject_row[\"bp_dia_end\"])\n",
    "\n",
    "\n",
    "            personal_data = personal_data.append(subject_row, ignore_index=True)  # adds the row to the \n",
    "\n",
    "ResultsFrame = pd.DataFrame({\"record\": record, 'PTTp': resultsPTT, \"PTTs\":resultsPTTs, \"PTTv\":resultsPTTv, \"HR\":HR, \"BP_sys\":BP_sys, \"BP_dia\":BP_dia, \"PTTp std\": PTTstd,\"PTTs std\": PTTsstd,\"PTTv std\": PTTvstd,})\n",
    "# Add two columns from df1 (A and B) to df2\n",
    "ResultsFrame = ResultsFrame.join(personal_data[['activity', 'gender','height', 'weight','age']])\n",
    "ResultsFrame = ResultsFrame.drop_duplicates(subset=[\"record\", \"PTTp\",\"HR\", \"BP_dia\"])  # deletes doublicates\n",
    "\n",
    "ResultsFrame = ResultsFrame[ResultsFrame['record'] != 's11_sit_start']  # 11 ist no good \n",
    "ResultsFrame = ResultsFrame[ResultsFrame['record'] != 's11_sit_end']\n",
    "\n",
    "# One-hot encode the gender variable\n",
    "ResultsFrame = pd.get_dummies(ResultsFrame, columns=['gender', 'activity'])\n",
    "\n",
    "ResultsFrame.to_csv('Results1.txt', sep='\\t', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hamilton_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
